{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: audioread is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU pinecone-client panns-inference datasets librosa python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 345/345 [00:00<00:00, 1.05MB/s]\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Downloading metadata: 100%|██████████| 1.61k/1.61k [00:00<00:00, 5.42MB/s]\n",
      "Downloading data: 100%|██████████| 387M/387M [01:22<00:00, 4.68MB/s]\n",
      "Downloading data: 100%|██████████| 387M/387M [01:25<00:00, 4.55MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [02:47<00:00, 167.59s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 235.32it/s]\n",
      "Generating train split: 100%|██████████| 2000/2000 [00:05<00:00, 377.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['filename', 'fold', 'target', 'category', 'esc10', 'src_file', 'take', 'audio'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset from huggingface model hub\n",
    "data = load_dataset(\"ashraq/esc50\", split=\"train\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the audio feature and display top three\n",
    "audios = data[\"audio\"]\n",
    "audios[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# select only the audio data from the dataset and store in a numpy array\n",
    "audios = np.array([a[\"array\"] for a in data[\"audio\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from panns_inference import AudioTagging\n",
    "\n",
    "# load the default model into the gpu.\n",
    "model = AudioTagging(checkpoint_path=None, device='cuda') # change device to cpu if a gpu is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# connect to pinecone environment\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"audio-search-demo\"\n",
    "\n",
    "# check if the audio-search index exists\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # create the index if it does not exist\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=2048,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "# connect to audio-search index we created\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# we will use batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(audios), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(audios))\n",
    "    # extract batch\n",
    "    batch = audios[i:i_end]\n",
    "    # generate embeddings for all the audios in the batch\n",
    "    _, emb = model.inference(batch)\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb.tolist()))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "# we set an audio number to select from the dataset\n",
    "audio_num = 400\n",
    "# get the audio data of the audio number\n",
    "query_audio = data[audio_num][\"audio\"][\"array\"]\n",
    "# get the category of the audio number\n",
    "category = data[audio_num][\"category\"]\n",
    "# print the category and play the audio\n",
    "print(\"Query Audio:\", category)\n",
    "Audio(query_audio, rate=44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
